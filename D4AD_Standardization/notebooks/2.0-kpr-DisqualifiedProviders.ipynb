{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# todo: set as env variable for raw main table\n",
    "rootpath = \"/hdd/work/d4ad_standardization/\"\n",
    "filepath = \"./D4AD_Standardization/data/raw/etpl_all_programsJune3.xls\"\n",
    "\n",
    "columns = [\n",
    "    \"NAME\",\n",
    "    \"NAME_1\",\n",
    "    \"DESCRIPTION\",\n",
    "    \"PREREQUISITES\",\n",
    "    \"FEATURESDESCRIPTION\",\n",
    "    \"STREET1\",\n",
    "    \"CITY\",\n",
    "    \"STATE\",\n",
    "    \"ZIP\",\n",
    "    \"WEBSITE\",\n",
    "    \"COUNTY\",\n",
    "    \"NONGOVAPPROVAL\",\n",
    "    \"STATECOMMENTS\",\n",
    "    \"CIPCODE\"\n",
    "]\n",
    "\n",
    "df = pd.read_excel(rootpath + filepath, usecols=columns)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# for test dev purposes, let's focus on a really small subset\n",
    "BATCH_SIZE = 50\n",
    "N = 20\n",
    "random_state = 42\n",
    "small_df = df.sample(n=N, random_state=random_state)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on a batch ...\n",
      "Star Technical Institute - Edison - PVS\n",
      "\t Star Technical Institute\n",
      "\t Edison\n",
      "\t PVS\n",
      "New Horizons of Central and Northern NJ, Inc. - Iselin - PVS\n",
      "\t New Horizons of Central and Northern NJ, Inc.\n",
      "\t Iselin\n",
      "\t PVS\n",
      "KeySkills Learning, Inc. - Maywood\n",
      "\t KeySkills Learning, Inc.\n",
      "\t Maywood\n",
      "Beyond Today - TP\n",
      "\t Beyond Today\n",
      "\t TP\n",
      "Rutgers Center for Innovation Education\n",
      "\t Rutgers Center for Innovation Education\n",
      "North Jersey Massage Training Center\n",
      "\t North Jersey Massage Training Center\n",
      "Essex County College Credit\n",
      "\t Essex County College Credit\n",
      "Rowan College at Gloucester County Division of Continuing Ed - WIA Title 2\n",
      "\t Rowan College at Gloucester County Division of Continuing Ed\n",
      "\t WIA Title 2\n",
      "Raritan Valley Community College - Non Credit\n",
      "\t Raritan Valley Community College\n",
      "\t Non Credit\n",
      "Newark Business Training Institute - TP\n",
      "\t Newark Business Training Institute\n",
      "\t TP\n",
      "ACECS, Inc. - PCS\n",
      "\t ACECS, Inc.\n",
      "\t PCS\n",
      "Rowan College at Burlington County - Non-credit\n",
      "\t Rowan College at Burlington County\n",
      "\t Non\n",
      "\t credit\n",
      "Universal Technical Institute Northeast, LLC - PCS\n",
      "\t Universal Technical Institute Northeast, LLC\n",
      "\t PCS\n",
      "The New York Code and Design Academy- Jersey City - PCS\n",
      "\t The New York Code and Design Academy- Jersey City\n",
      "\t PCS\n",
      "CDM Technical Training Institute, Inc. - Phillipsburg - PVS\n",
      "\t CDM Technical Training Institute, Inc.\n",
      "\t Phillipsburg\n",
      "\t PVS\n",
      "1st Security Preparation & Placement - PVS\n",
      "\t 1st Security Preparation & Placement\n",
      "\t PVS\n",
      "Union County College - Academic Programs\n",
      "\t Union County College\n",
      "\t Academic Programs\n",
      "Anthem Institute - Jersey City - PVS\n",
      "\t Anthem Institute\n",
      "\t Jersey City\n",
      "\t PVS\n",
      "Union County College - Adult & Continuing ED./Industry Business Institute\n",
      "\t Union County College\n",
      "\t Adult & Continuing ED./Industry Business Institute\n",
      "Raritan Valley Community College - Non Credit\n",
      "\t Raritan Valley Community College\n",
      "\t Non Credit\n"
     ]
    }
   ],
   "source": [
    "def batches_of_docs(df, column_index=0, nlp=nlp, batch_size=BATCH_SIZE, disable=[\"parser\",\"ner\", \"entity_linker\"]):\n",
    "    yield nlp.pipe(df.iloc[:,column_index].values,\n",
    "                   batch_size=batch_size,\n",
    "                   disable=disable)\n",
    "\n",
    "def contents_of(matches, doc, matcher_spans_content=False):\n",
    "    # if matcher_spans_content=False then the matcher\n",
    "    # indicates where content is not and we span the\n",
    "    # regions excluded by the matcher\n",
    "    print(doc)\n",
    "    if not matcher_spans_content:\n",
    "        match_start = 0\n",
    "        for match in matches:\n",
    "            match_end = match[1]\n",
    "            print(\"\\t\", doc[match_start:match_end])\n",
    "            yield doc[match_start:match_end]\n",
    "            match_start = match[2]\n",
    "        print('\\t', doc[match_start:])\n",
    "        yield doc[match_start:]\n",
    "\n",
    "\n",
    "patterns =\\\n",
    "    [\n",
    "        # these break up small_df.iloc[0] into unstandardized tokens\n",
    "        #[{'POS': 'PUNCT'}],  # fails in later samples\n",
    "        [{'POS': 'CCONJ'}],\n",
    "        # modifiction that breaks up small_df.iloc[7]\n",
    "        [{'ORTH': '/'}],\n",
    "        # modifiction that combines small_df.iloc[15], [1]\n",
    "        [{'ORTH': ','}],\n",
    "        # modifiction seen generally past 50 or os\n",
    "        [{'ORTH': ';'}],\n",
    "        # TODO: fix this to work, i could be special casing too early/improperly\n",
    "        # modifiction seen random_state*2\n",
    "        [{'IS_SPACE': True}], # captures present spaces after tokenizations\n",
    "    ]\n",
    "\n",
    "patterns =\\\n",
    "    [\n",
    "        [{'ORTH': '-'}],\n",
    "    ]\n",
    "\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"DoNotStandardize\", patterns)\n",
    "\n",
    "\n",
    "for a_batch in batches_of_docs(small_df):\n",
    "    print('on a batch ...')\n",
    "    for doc, matches in matcher.pipe(a_batch, return_matches=True, batch_size=50):\n",
    "        for content in contents_of(matches, doc):\n",
    "            pass\n",
    "    \"\"\"\n",
    "    for match in matcher.pipe(batch, batch_size=50):\n",
    "        print(' had a match ... ')\n",
    "        for content in contents_of(match):\n",
    "            print(content)\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
